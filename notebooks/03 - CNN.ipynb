{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1cxGyZhunHDb"
   },
   "source": [
    "# Rede Neural Convolucional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EZPp23HYnHDf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1555804000215,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "cGMOJq80nHDs",
    "outputId": "738ead35-2010-4b5a-dc8a-84c0f90d4908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2723,
     "status": "ok",
     "timestamp": 1555804002045,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "8XhxVpVFnHD3",
    "outputId": "e79a4a64-9185-4711-f478-eb7f963ce008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Carregar os datasets\n",
    "\n",
    "transform=transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "dataset_test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3984,
     "status": "ok",
     "timestamp": 1555804003324,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "QN7Lbm84nHD8",
    "outputId": "b41c6437-9d90-4c6e-f3cd-da0784612dc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "train = DataLoader(dataset=dataset_train, shuffle=True, batch_size=200)\n",
    "test_loader = DataLoader(dataset=dataset_test, shuffle=False, batch_size=1000)\n",
    "test, validation = [], []\n",
    "\n",
    "for index, element in enumerate(test_loader):\n",
    "  if index/len(test_loader) < 0.49:\n",
    "    test.append(element)\n",
    "  else:\n",
    "    validation.append(element)\n",
    "\n",
    "test_size, validation_size = len(test) * 1000, len(validation) * 1000\n",
    "print(test_size, validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wb6DKramnHEA"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_dropout = nn.Dropout(p=0.5)\n",
    "        self.cn_dropout = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 32, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*5*5, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cn_dropout(self.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.cn_dropout(self.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = self.cn_dropout(self.relu(self.conv3_bn(self.conv3(x))))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(-1, 32*5*5)\n",
    "        \n",
    "        x = self.fc_dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc_dropout(self.relu(self.fc2(x)))\n",
    "        x = self.fc_dropout(self.relu(self.fc3(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8181,
     "status": "ok",
     "timestamp": 1555804007565,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "NuYrQiH3nHEE",
    "outputId": "e19f8341-0c30-4f2d-d904-8eaa95a65533",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      "  (fc_dropout): Dropout(p=0.5)\n",
      "  (cn_dropout): Dropout2d(p=0.2)\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=800, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2, weight_decay=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tWUWf9p8nHEJ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "def one_hot(results):\n",
    "    results = results.cpu().detach().numpy().tolist()\n",
    "    return results.index(max(results))\n",
    "\n",
    "def train_model(model, epochs, train, test):\n",
    "    global test_size\n",
    "    best_model, train_losses, test_acc = model, [], []\n",
    "    min_error = sys.float_info.max\n",
    "    \n",
    "    train_inputs, train_labels = [], []\n",
    "    for _, (inputs, labels) in enumerate(train):\n",
    "        train_inputs.append(inputs.to(device))\n",
    "        train_labels.append(labels.to(device))\n",
    "    \n",
    "    test_inputs, test_labels = [], []\n",
    "    for _, (inputs, labels) in enumerate(test):\n",
    "        test_inputs.append(inputs.to(device))\n",
    "        test_labels.append(labels.to(device))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training Set\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(zip(train_inputs, train_labels), 0):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(inputs)\n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        train_losses.append(running_loss / (50000/200))\n",
    "        \n",
    "        # Test set\n",
    "        model.eval()\n",
    "        hits = 0\n",
    "        for i, (inputs, labels) in enumerate(zip(test_inputs, test_labels), 0):\n",
    "            y_pred = model(inputs)\n",
    "            for i, (pred, label) in enumerate(zip(y_pred, labels)):\n",
    "                if one_hot(pred)==label.item():\n",
    "                    hits+=1\n",
    "                    \n",
    "        test_acc.append(hits / test_size * 100)\n",
    "        if test_acc[-1] <= min_error:\n",
    "            min_error = test_acc[-1]\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        print(\"Loss at epoch [\"+ str(epoch + 1) +\"]: \"+ str(train_losses[-1]) +\" (Train Set)\")\n",
    "        print(\"Accuracy at epoch [\" + str(epoch + 1) + \"]:\"+str(test_acc[-1])+\"% (Test Set)\")\n",
    "        print('\\n')    \n",
    "            \n",
    "    return best_model, train_losses, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCcA5tlMnHEM"
   },
   "source": [
    "# Trainamento do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 27217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973089,
     "status": "ok",
     "timestamp": 1555804972489,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "V6K4tfJ4nHEN",
    "outputId": "3eb00289-8cad-4626-d7b8-b600a821c195",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [1]: 2.304200301170349 (Train Set)\n",
      "Accuracy at epoch [1]:17.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [2]: 2.298341275215149 (Train Set)\n",
      "Accuracy at epoch [2]:21.32% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [3]: 2.2897805490493774 (Train Set)\n",
      "Accuracy at epoch [3]:25.1% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [4]: 2.269992081642151 (Train Set)\n",
      "Accuracy at epoch [4]:28.999999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [5]: 2.24306596660614 (Train Set)\n",
      "Accuracy at epoch [5]:32.26% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [6]: 2.2253772716522215 (Train Set)\n",
      "Accuracy at epoch [6]:33.32% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [7]: 2.2093800201416016 (Train Set)\n",
      "Accuracy at epoch [7]:33.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [8]: 2.196049430847168 (Train Set)\n",
      "Accuracy at epoch [8]:36.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [9]: 2.1797677478790285 (Train Set)\n",
      "Accuracy at epoch [9]:37.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [10]: 2.1715503187179563 (Train Set)\n",
      "Accuracy at epoch [10]:39.519999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [11]: 2.157576295852661 (Train Set)\n",
      "Accuracy at epoch [11]:39.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [12]: 2.1489165601730345 (Train Set)\n",
      "Accuracy at epoch [12]:40.48% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [13]: 2.1393099498748778 (Train Set)\n",
      "Accuracy at epoch [13]:40.760000000000005% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [14]: 2.126437145233154 (Train Set)\n",
      "Accuracy at epoch [14]:42.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [15]: 2.119685745239258 (Train Set)\n",
      "Accuracy at epoch [15]:43.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [16]: 2.1124168252944946 (Train Set)\n",
      "Accuracy at epoch [16]:43.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [17]: 2.1060880212783815 (Train Set)\n",
      "Accuracy at epoch [17]:44.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [18]: 2.0936521973609925 (Train Set)\n",
      "Accuracy at epoch [18]:44.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [19]: 2.085983322620392 (Train Set)\n",
      "Accuracy at epoch [19]:45.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [20]: 2.0817806339263916 (Train Set)\n",
      "Accuracy at epoch [20]:46.88% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [21]: 2.07483588886261 (Train Set)\n",
      "Accuracy at epoch [21]:47.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [22]: 2.0738579931259156 (Train Set)\n",
      "Accuracy at epoch [22]:47.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [23]: 2.0703204236030577 (Train Set)\n",
      "Accuracy at epoch [23]:48.559999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [24]: 2.069146189212799 (Train Set)\n",
      "Accuracy at epoch [24]:48.74% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [25]: 2.060960174560547 (Train Set)\n",
      "Accuracy at epoch [25]:49.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [26]: 2.0546979150772096 (Train Set)\n",
      "Accuracy at epoch [26]:49.480000000000004% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [27]: 2.0470082087516785 (Train Set)\n",
      "Accuracy at epoch [27]:50.239999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [28]: 2.042632243156433 (Train Set)\n",
      "Accuracy at epoch [28]:49.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [29]: 2.039712277889252 (Train Set)\n",
      "Accuracy at epoch [29]:51.18000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [30]: 2.030749108791351 (Train Set)\n",
      "Accuracy at epoch [30]:50.519999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [31]: 2.0215843467712404 (Train Set)\n",
      "Accuracy at epoch [31]:52.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [32]: 2.021779233932495 (Train Set)\n",
      "Accuracy at epoch [32]:51.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [33]: 2.024881538391113 (Train Set)\n",
      "Accuracy at epoch [33]:52.76% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [34]: 2.021102099895477 (Train Set)\n",
      "Accuracy at epoch [34]:52.339999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [35]: 2.0110040044784547 (Train Set)\n",
      "Accuracy at epoch [35]:53.059999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [36]: 2.006231008052826 (Train Set)\n",
      "Accuracy at epoch [36]:53.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [37]: 2.006468816280365 (Train Set)\n",
      "Accuracy at epoch [37]:53.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [38]: 1.9963070616722107 (Train Set)\n",
      "Accuracy at epoch [38]:53.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [39]: 1.9991955919265747 (Train Set)\n",
      "Accuracy at epoch [39]:54.339999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [40]: 1.9911390795707702 (Train Set)\n",
      "Accuracy at epoch [40]:53.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [41]: 1.9942175006866456 (Train Set)\n",
      "Accuracy at epoch [41]:53.559999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [42]: 1.987473527431488 (Train Set)\n",
      "Accuracy at epoch [42]:55.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [43]: 1.976475670337677 (Train Set)\n",
      "Accuracy at epoch [43]:55.96% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [44]: 1.9748953976631165 (Train Set)\n",
      "Accuracy at epoch [44]:55.67999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [45]: 1.9785610237121583 (Train Set)\n",
      "Accuracy at epoch [45]:55.60000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [46]: 1.968995312690735 (Train Set)\n",
      "Accuracy at epoch [46]:56.32% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [47]: 1.9749273624420165 (Train Set)\n",
      "Accuracy at epoch [47]:56.879999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [48]: 1.9704696655273437 (Train Set)\n",
      "Accuracy at epoch [48]:56.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [49]: 1.9569960408210754 (Train Set)\n",
      "Accuracy at epoch [49]:56.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [50]: 1.9569563941955566 (Train Set)\n",
      "Accuracy at epoch [50]:57.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [51]: 1.9534944314956666 (Train Set)\n",
      "Accuracy at epoch [51]:56.74% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [52]: 1.9546931643486023 (Train Set)\n",
      "Accuracy at epoch [52]:57.49999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [53]: 1.948692561149597 (Train Set)\n",
      "Accuracy at epoch [53]:58.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [54]: 1.9476754212379455 (Train Set)\n",
      "Accuracy at epoch [54]:58.699999999999996% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [55]: 1.944798243999481 (Train Set)\n",
      "Accuracy at epoch [55]:58.120000000000005% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [56]: 1.9434882502555848 (Train Set)\n",
      "Accuracy at epoch [56]:58.599999999999994% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [57]: 1.944771746635437 (Train Set)\n",
      "Accuracy at epoch [57]:58.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [58]: 1.939228391647339 (Train Set)\n",
      "Accuracy at epoch [58]:58.540000000000006% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [59]: 1.9269615559577942 (Train Set)\n",
      "Accuracy at epoch [59]:59.38% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [60]: 1.9289453864097594 (Train Set)\n",
      "Accuracy at epoch [60]:59.440000000000005% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [61]: 1.923949945449829 (Train Set)\n",
      "Accuracy at epoch [61]:59.919999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [62]: 1.9215522332191468 (Train Set)\n",
      "Accuracy at epoch [62]:60.31999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [63]: 1.9227198734283448 (Train Set)\n",
      "Accuracy at epoch [63]:59.74% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [64]: 1.922381489276886 (Train Set)\n",
      "Accuracy at epoch [64]:59.919999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [65]: 1.9176875705718994 (Train Set)\n",
      "Accuracy at epoch [65]:60.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [66]: 1.914093412399292 (Train Set)\n",
      "Accuracy at epoch [66]:60.81999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [67]: 1.914093138217926 (Train Set)\n",
      "Accuracy at epoch [67]:60.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [68]: 1.9083661680221558 (Train Set)\n",
      "Accuracy at epoch [68]:60.160000000000004% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [69]: 1.9112818460464478 (Train Set)\n",
      "Accuracy at epoch [69]:60.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [70]: 1.9062078409194947 (Train Set)\n",
      "Accuracy at epoch [70]:60.9% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [71]: 1.8968500289916992 (Train Set)\n",
      "Accuracy at epoch [71]:59.62% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [72]: 1.8997424178123474 (Train Set)\n",
      "Accuracy at epoch [72]:61.919999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [73]: 1.896859094619751 (Train Set)\n",
      "Accuracy at epoch [73]:61.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [74]: 1.8915983610153198 (Train Set)\n",
      "Accuracy at epoch [74]:61.419999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [75]: 1.8899275035858154 (Train Set)\n",
      "Accuracy at epoch [75]:60.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [76]: 1.8915588488578796 (Train Set)\n",
      "Accuracy at epoch [76]:61.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [77]: 1.8890271825790406 (Train Set)\n",
      "Accuracy at epoch [77]:62.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [78]: 1.885044029712677 (Train Set)\n",
      "Accuracy at epoch [78]:61.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [79]: 1.881102478981018 (Train Set)\n",
      "Accuracy at epoch [79]:62.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [80]: 1.8871725311279297 (Train Set)\n",
      "Accuracy at epoch [80]:62.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [81]: 1.8789073505401612 (Train Set)\n",
      "Accuracy at epoch [81]:62.7% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [82]: 1.8662556405067443 (Train Set)\n",
      "Accuracy at epoch [82]:63.4% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [83]: 1.8762225041389464 (Train Set)\n",
      "Accuracy at epoch [83]:62.419999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [84]: 1.8694186601638794 (Train Set)\n",
      "Accuracy at epoch [84]:62.6% (Test Set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [85]: 1.8645293455123901 (Train Set)\n",
      "Accuracy at epoch [85]:63.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [86]: 1.8698242015838622 (Train Set)\n",
      "Accuracy at epoch [86]:62.739999999999995% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [87]: 1.8654077382087708 (Train Set)\n",
      "Accuracy at epoch [87]:63.38% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [88]: 1.8686196656227112 (Train Set)\n",
      "Accuracy at epoch [88]:63.54% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [89]: 1.8641448392868043 (Train Set)\n",
      "Accuracy at epoch [89]:62.86000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [90]: 1.8588122205734252 (Train Set)\n",
      "Accuracy at epoch [90]:63.580000000000005% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [91]: 1.8569966650009155 (Train Set)\n",
      "Accuracy at epoch [91]:64.4% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [92]: 1.8438950595855712 (Train Set)\n",
      "Accuracy at epoch [92]:64.60000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [93]: 1.8549888281822204 (Train Set)\n",
      "Accuracy at epoch [93]:64.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [94]: 1.8555562686920166 (Train Set)\n",
      "Accuracy at epoch [94]:64.88000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [95]: 1.8512075896263123 (Train Set)\n",
      "Accuracy at epoch [95]:65.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [96]: 1.8530906958580018 (Train Set)\n",
      "Accuracy at epoch [96]:64.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [97]: 1.8432747869491577 (Train Set)\n",
      "Accuracy at epoch [97]:64.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [98]: 1.8486387195587157 (Train Set)\n",
      "Accuracy at epoch [98]:65.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [99]: 1.8421530270576476 (Train Set)\n",
      "Accuracy at epoch [99]:65.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [100]: 1.837712513923645 (Train Set)\n",
      "Accuracy at epoch [100]:65.96% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [101]: 1.8387638177871704 (Train Set)\n",
      "Accuracy at epoch [101]:65.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [102]: 1.8385739178657532 (Train Set)\n",
      "Accuracy at epoch [102]:63.62% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [103]: 1.8340672187805176 (Train Set)\n",
      "Accuracy at epoch [103]:66.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [104]: 1.8358559045791627 (Train Set)\n",
      "Accuracy at epoch [104]:66.24% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [105]: 1.83703338098526 (Train Set)\n",
      "Accuracy at epoch [105]:66.3% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [106]: 1.830148024082184 (Train Set)\n",
      "Accuracy at epoch [106]:66.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [107]: 1.829121160030365 (Train Set)\n",
      "Accuracy at epoch [107]:64.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [108]: 1.827793517112732 (Train Set)\n",
      "Accuracy at epoch [108]:66.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [109]: 1.823211450099945 (Train Set)\n",
      "Accuracy at epoch [109]:66.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [110]: 1.820226779937744 (Train Set)\n",
      "Accuracy at epoch [110]:66.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [111]: 1.8249001302719117 (Train Set)\n",
      "Accuracy at epoch [111]:65.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [112]: 1.8284483575820922 (Train Set)\n",
      "Accuracy at epoch [112]:66.47999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [113]: 1.8196655626296998 (Train Set)\n",
      "Accuracy at epoch [113]:67.4% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [114]: 1.816698932170868 (Train Set)\n",
      "Accuracy at epoch [114]:66.75999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [115]: 1.815243348121643 (Train Set)\n",
      "Accuracy at epoch [115]:67.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [116]: 1.8110073847770691 (Train Set)\n",
      "Accuracy at epoch [116]:67.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [117]: 1.8105882773399353 (Train Set)\n",
      "Accuracy at epoch [117]:67.97999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [118]: 1.811470244884491 (Train Set)\n",
      "Accuracy at epoch [118]:66.60000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [119]: 1.8108422751426696 (Train Set)\n",
      "Accuracy at epoch [119]:67.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [120]: 1.8075909452438355 (Train Set)\n",
      "Accuracy at epoch [120]:67.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [121]: 1.807709831237793 (Train Set)\n",
      "Accuracy at epoch [121]:67.7% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [122]: 1.805008312702179 (Train Set)\n",
      "Accuracy at epoch [122]:67.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [123]: 1.8079618391990662 (Train Set)\n",
      "Accuracy at epoch [123]:67.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [124]: 1.8066968650817872 (Train Set)\n",
      "Accuracy at epoch [124]:67.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [125]: 1.804467378616333 (Train Set)\n",
      "Accuracy at epoch [125]:65.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [126]: 1.7984993524551391 (Train Set)\n",
      "Accuracy at epoch [126]:67.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [127]: 1.7996004309654237 (Train Set)\n",
      "Accuracy at epoch [127]:65.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [128]: 1.7972383213043213 (Train Set)\n",
      "Accuracy at epoch [128]:67.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [129]: 1.787854594707489 (Train Set)\n",
      "Accuracy at epoch [129]:68.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [130]: 1.786366063117981 (Train Set)\n",
      "Accuracy at epoch [130]:67.32000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [131]: 1.7933015403747559 (Train Set)\n",
      "Accuracy at epoch [131]:67.25999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [132]: 1.7856726722717284 (Train Set)\n",
      "Accuracy at epoch [132]:68.26% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [133]: 1.79098317193985 (Train Set)\n",
      "Accuracy at epoch [133]:68.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [134]: 1.7969561758041381 (Train Set)\n",
      "Accuracy at epoch [134]:68.78% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [135]: 1.7820797486305238 (Train Set)\n",
      "Accuracy at epoch [135]:67.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [136]: 1.7880504665374757 (Train Set)\n",
      "Accuracy at epoch [136]:69.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [137]: 1.7807931909561157 (Train Set)\n",
      "Accuracy at epoch [137]:68.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [138]: 1.784080325126648 (Train Set)\n",
      "Accuracy at epoch [138]:68.82000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [139]: 1.7856251678466797 (Train Set)\n",
      "Accuracy at epoch [139]:68.66% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [140]: 1.7783437089920044 (Train Set)\n",
      "Accuracy at epoch [140]:69.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [141]: 1.776374670982361 (Train Set)\n",
      "Accuracy at epoch [141]:69.39999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [142]: 1.7786243405342101 (Train Set)\n",
      "Accuracy at epoch [142]:68.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [143]: 1.7806781458854675 (Train Set)\n",
      "Accuracy at epoch [143]:69.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [144]: 1.777780698299408 (Train Set)\n",
      "Accuracy at epoch [144]:69.54% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [145]: 1.7657009334564209 (Train Set)\n",
      "Accuracy at epoch [145]:69.32000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [146]: 1.7729633121490478 (Train Set)\n",
      "Accuracy at epoch [146]:69.88% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [147]: 1.7810546445846558 (Train Set)\n",
      "Accuracy at epoch [147]:69.89999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [148]: 1.7726643652915954 (Train Set)\n",
      "Accuracy at epoch [148]:68.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [149]: 1.7645631709098817 (Train Set)\n",
      "Accuracy at epoch [149]:69.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [150]: 1.7647924041748047 (Train Set)\n",
      "Accuracy at epoch [150]:69.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [151]: 1.7692250952720643 (Train Set)\n",
      "Accuracy at epoch [151]:70.38% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [152]: 1.7672062010765075 (Train Set)\n",
      "Accuracy at epoch [152]:69.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [153]: 1.766700719356537 (Train Set)\n",
      "Accuracy at epoch [153]:70.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [154]: 1.7655702018737793 (Train Set)\n",
      "Accuracy at epoch [154]:70.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [155]: 1.7621447987556458 (Train Set)\n",
      "Accuracy at epoch [155]:70.39999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [156]: 1.7696742777824401 (Train Set)\n",
      "Accuracy at epoch [156]:70.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [157]: 1.7630728945732117 (Train Set)\n",
      "Accuracy at epoch [157]:69.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [158]: 1.7581793456077575 (Train Set)\n",
      "Accuracy at epoch [158]:69.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [159]: 1.7597678651809692 (Train Set)\n",
      "Accuracy at epoch [159]:70.17999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [160]: 1.7576229948997497 (Train Set)\n",
      "Accuracy at epoch [160]:70.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [161]: 1.7598856263160705 (Train Set)\n",
      "Accuracy at epoch [161]:70.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [162]: 1.7550211749076843 (Train Set)\n",
      "Accuracy at epoch [162]:70.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [163]: 1.752515221118927 (Train Set)\n",
      "Accuracy at epoch [163]:70.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [164]: 1.7478578023910523 (Train Set)\n",
      "Accuracy at epoch [164]:70.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [165]: 1.7516740546226501 (Train Set)\n",
      "Accuracy at epoch [165]:70.3% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [166]: 1.7550903420448303 (Train Set)\n",
      "Accuracy at epoch [166]:71.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [167]: 1.7424223413467408 (Train Set)\n",
      "Accuracy at epoch [167]:68.97999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [168]: 1.7449255838394164 (Train Set)\n",
      "Accuracy at epoch [168]:70.66% (Test Set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [169]: 1.7511504397392272 (Train Set)\n",
      "Accuracy at epoch [169]:70.54% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [170]: 1.7497923130989075 (Train Set)\n",
      "Accuracy at epoch [170]:70.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [171]: 1.7413305802345276 (Train Set)\n",
      "Accuracy at epoch [171]:68.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [172]: 1.740158772468567 (Train Set)\n",
      "Accuracy at epoch [172]:70.82000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [173]: 1.7464600200653075 (Train Set)\n",
      "Accuracy at epoch [173]:70.89999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [174]: 1.7368574390411378 (Train Set)\n",
      "Accuracy at epoch [174]:70.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [175]: 1.7333353996276855 (Train Set)\n",
      "Accuracy at epoch [175]:69.89999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [176]: 1.7453439178466796 (Train Set)\n",
      "Accuracy at epoch [176]:70.19999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [177]: 1.7340793223381044 (Train Set)\n",
      "Accuracy at epoch [177]:71.16% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [178]: 1.7374999713897705 (Train Set)\n",
      "Accuracy at epoch [178]:71.41999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [179]: 1.7408824038505555 (Train Set)\n",
      "Accuracy at epoch [179]:70.39999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [180]: 1.7421806659698487 (Train Set)\n",
      "Accuracy at epoch [180]:71.61999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [181]: 1.7305940613746642 (Train Set)\n",
      "Accuracy at epoch [181]:71.38% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [182]: 1.7311720485687256 (Train Set)\n",
      "Accuracy at epoch [182]:72.16% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [183]: 1.727627254486084 (Train Set)\n",
      "Accuracy at epoch [183]:71.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [184]: 1.727674674987793 (Train Set)\n",
      "Accuracy at epoch [184]:71.82% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [185]: 1.726262680530548 (Train Set)\n",
      "Accuracy at epoch [185]:72.3% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [186]: 1.7352634134292602 (Train Set)\n",
      "Accuracy at epoch [186]:71.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [187]: 1.7299901700019837 (Train Set)\n",
      "Accuracy at epoch [187]:72.32% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [188]: 1.7304032993316651 (Train Set)\n",
      "Accuracy at epoch [188]:72.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [189]: 1.7316419863700867 (Train Set)\n",
      "Accuracy at epoch [189]:71.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [190]: 1.7267069826126098 (Train Set)\n",
      "Accuracy at epoch [190]:72.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [191]: 1.728965621471405 (Train Set)\n",
      "Accuracy at epoch [191]:72.08% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [192]: 1.7262703418731689 (Train Set)\n",
      "Accuracy at epoch [192]:72.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [193]: 1.7179485816955566 (Train Set)\n",
      "Accuracy at epoch [193]:72.48% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [194]: 1.7256172304153443 (Train Set)\n",
      "Accuracy at epoch [194]:71.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [195]: 1.7187072982788085 (Train Set)\n",
      "Accuracy at epoch [195]:71.41999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [196]: 1.7203843393325806 (Train Set)\n",
      "Accuracy at epoch [196]:70.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [197]: 1.7235661888122558 (Train Set)\n",
      "Accuracy at epoch [197]:72.32% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [198]: 1.7178418521881103 (Train Set)\n",
      "Accuracy at epoch [198]:71.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [199]: 1.71894575548172 (Train Set)\n",
      "Accuracy at epoch [199]:72.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [200]: 1.7202634167671205 (Train Set)\n",
      "Accuracy at epoch [200]:71.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [201]: 1.721876893043518 (Train Set)\n",
      "Accuracy at epoch [201]:72.78% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [202]: 1.715363013267517 (Train Set)\n",
      "Accuracy at epoch [202]:72.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [203]: 1.714314372062683 (Train Set)\n",
      "Accuracy at epoch [203]:72.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [204]: 1.7139921584129334 (Train Set)\n",
      "Accuracy at epoch [204]:72.54% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [205]: 1.707589413166046 (Train Set)\n",
      "Accuracy at epoch [205]:72.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [206]: 1.7153030190467835 (Train Set)\n",
      "Accuracy at epoch [206]:72.61999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [207]: 1.7145030641555785 (Train Set)\n",
      "Accuracy at epoch [207]:73.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [208]: 1.7090307507514955 (Train Set)\n",
      "Accuracy at epoch [208]:73.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [209]: 1.705034483909607 (Train Set)\n",
      "Accuracy at epoch [209]:71.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [210]: 1.7095906829833984 (Train Set)\n",
      "Accuracy at epoch [210]:73.1% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [211]: 1.7097671546936035 (Train Set)\n",
      "Accuracy at epoch [211]:72.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [212]: 1.7044559693336487 (Train Set)\n",
      "Accuracy at epoch [212]:73.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [213]: 1.700110846042633 (Train Set)\n",
      "Accuracy at epoch [213]:72.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [214]: 1.7063867573738098 (Train Set)\n",
      "Accuracy at epoch [214]:72.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [215]: 1.7096214332580566 (Train Set)\n",
      "Accuracy at epoch [215]:72.76% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [216]: 1.7004431366920472 (Train Set)\n",
      "Accuracy at epoch [216]:73.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [217]: 1.6992776255607605 (Train Set)\n",
      "Accuracy at epoch [217]:69.69999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [218]: 1.6979095287322998 (Train Set)\n",
      "Accuracy at epoch [218]:73.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [219]: 1.7049901928901672 (Train Set)\n",
      "Accuracy at epoch [219]:73.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [220]: 1.697691418647766 (Train Set)\n",
      "Accuracy at epoch [220]:73.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [221]: 1.7008927946090697 (Train Set)\n",
      "Accuracy at epoch [221]:72.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [222]: 1.7011523609161376 (Train Set)\n",
      "Accuracy at epoch [222]:72.82% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [223]: 1.6890612998008727 (Train Set)\n",
      "Accuracy at epoch [223]:73.61999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [224]: 1.6988457169532776 (Train Set)\n",
      "Accuracy at epoch [224]:73.08% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [225]: 1.6972966060638428 (Train Set)\n",
      "Accuracy at epoch [225]:73.74000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [226]: 1.690851364135742 (Train Set)\n",
      "Accuracy at epoch [226]:74.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [227]: 1.6939023900032044 (Train Set)\n",
      "Accuracy at epoch [227]:72.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [228]: 1.6947894296646118 (Train Set)\n",
      "Accuracy at epoch [228]:73.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [229]: 1.688363974571228 (Train Set)\n",
      "Accuracy at epoch [229]:73.82% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [230]: 1.6911643333435058 (Train Set)\n",
      "Accuracy at epoch [230]:74.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [231]: 1.6996985063552856 (Train Set)\n",
      "Accuracy at epoch [231]:74.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [232]: 1.694060715675354 (Train Set)\n",
      "Accuracy at epoch [232]:73.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [233]: 1.696356231212616 (Train Set)\n",
      "Accuracy at epoch [233]:74.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [234]: 1.690658336162567 (Train Set)\n",
      "Accuracy at epoch [234]:74.1% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [235]: 1.6906049027442933 (Train Set)\n",
      "Accuracy at epoch [235]:74.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [236]: 1.6832827081680297 (Train Set)\n",
      "Accuracy at epoch [236]:73.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [237]: 1.6870139050483703 (Train Set)\n",
      "Accuracy at epoch [237]:72.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [238]: 1.6902947158813477 (Train Set)\n",
      "Accuracy at epoch [238]:73.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [239]: 1.6881590609550476 (Train Set)\n",
      "Accuracy at epoch [239]:74.08% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [240]: 1.6750248947143556 (Train Set)\n",
      "Accuracy at epoch [240]:74.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [241]: 1.6833276352882385 (Train Set)\n",
      "Accuracy at epoch [241]:74.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [242]: 1.672054805278778 (Train Set)\n",
      "Accuracy at epoch [242]:74.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [243]: 1.686876872062683 (Train Set)\n",
      "Accuracy at epoch [243]:74.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [244]: 1.6852768077850342 (Train Set)\n",
      "Accuracy at epoch [244]:73.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [245]: 1.6782810244560242 (Train Set)\n",
      "Accuracy at epoch [245]:74.11999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [246]: 1.67651131772995 (Train Set)\n",
      "Accuracy at epoch [246]:74.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [247]: 1.6802974643707276 (Train Set)\n",
      "Accuracy at epoch [247]:74.74% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [248]: 1.679823320388794 (Train Set)\n",
      "Accuracy at epoch [248]:74.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [249]: 1.6756041493415832 (Train Set)\n",
      "Accuracy at epoch [249]:74.33999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [250]: 1.6709373049736023 (Train Set)\n",
      "Accuracy at epoch [250]:74.46000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [251]: 1.671286744594574 (Train Set)\n",
      "Accuracy at epoch [251]:73.82% (Test Set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [252]: 1.6757820525169373 (Train Set)\n",
      "Accuracy at epoch [252]:74.74% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [253]: 1.677974048614502 (Train Set)\n",
      "Accuracy at epoch [253]:75.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [254]: 1.672878727912903 (Train Set)\n",
      "Accuracy at epoch [254]:74.76% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [255]: 1.6687656908035278 (Train Set)\n",
      "Accuracy at epoch [255]:74.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [256]: 1.6739274339675903 (Train Set)\n",
      "Accuracy at epoch [256]:74.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [257]: 1.6649606127738952 (Train Set)\n",
      "Accuracy at epoch [257]:74.76% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [258]: 1.6644905681610107 (Train Set)\n",
      "Accuracy at epoch [258]:74.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [259]: 1.6783056325912475 (Train Set)\n",
      "Accuracy at epoch [259]:74.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [260]: 1.6666743307113647 (Train Set)\n",
      "Accuracy at epoch [260]:74.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [261]: 1.6557825136184692 (Train Set)\n",
      "Accuracy at epoch [261]:75.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [262]: 1.6648182339668274 (Train Set)\n",
      "Accuracy at epoch [262]:75.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [263]: 1.6674036664962768 (Train Set)\n",
      "Accuracy at epoch [263]:74.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [264]: 1.664348114490509 (Train Set)\n",
      "Accuracy at epoch [264]:74.9% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [265]: 1.6710610036849975 (Train Set)\n",
      "Accuracy at epoch [265]:75.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [266]: 1.6695752172470093 (Train Set)\n",
      "Accuracy at epoch [266]:74.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [267]: 1.665197096824646 (Train Set)\n",
      "Accuracy at epoch [267]:74.76% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [268]: 1.6639686298370362 (Train Set)\n",
      "Accuracy at epoch [268]:74.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [269]: 1.6639207186698914 (Train Set)\n",
      "Accuracy at epoch [269]:74.56% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [270]: 1.6718812794685365 (Train Set)\n",
      "Accuracy at epoch [270]:74.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [271]: 1.6649879417419433 (Train Set)\n",
      "Accuracy at epoch [271]:75.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [272]: 1.6552998948097228 (Train Set)\n",
      "Accuracy at epoch [272]:75.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [273]: 1.6509249019622803 (Train Set)\n",
      "Accuracy at epoch [273]:75.26% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [274]: 1.6524782433509826 (Train Set)\n",
      "Accuracy at epoch [274]:74.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [275]: 1.6569187693595886 (Train Set)\n",
      "Accuracy at epoch [275]:75.33999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [276]: 1.656888050556183 (Train Set)\n",
      "Accuracy at epoch [276]:75.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [277]: 1.6659300246238709 (Train Set)\n",
      "Accuracy at epoch [277]:75.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [278]: 1.6576642298698425 (Train Set)\n",
      "Accuracy at epoch [278]:74.94% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [279]: 1.6511094107627868 (Train Set)\n",
      "Accuracy at epoch [279]:74.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [280]: 1.6593568654060364 (Train Set)\n",
      "Accuracy at epoch [280]:75.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [281]: 1.6534277267456055 (Train Set)\n",
      "Accuracy at epoch [281]:72.66% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [282]: 1.6593480496406554 (Train Set)\n",
      "Accuracy at epoch [282]:75.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [283]: 1.657300145626068 (Train Set)\n",
      "Accuracy at epoch [283]:75.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [284]: 1.6589364762306213 (Train Set)\n",
      "Accuracy at epoch [284]:74.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [285]: 1.6592104759216308 (Train Set)\n",
      "Accuracy at epoch [285]:75.48% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [286]: 1.6544512004852294 (Train Set)\n",
      "Accuracy at epoch [286]:74.66000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [287]: 1.6541858448982238 (Train Set)\n",
      "Accuracy at epoch [287]:75.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [288]: 1.653291673183441 (Train Set)\n",
      "Accuracy at epoch [288]:74.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [289]: 1.6500134949684142 (Train Set)\n",
      "Accuracy at epoch [289]:74.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [290]: 1.6501174592971801 (Train Set)\n",
      "Accuracy at epoch [290]:74.83999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [291]: 1.653384530067444 (Train Set)\n",
      "Accuracy at epoch [291]:75.1% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [292]: 1.644240553379059 (Train Set)\n",
      "Accuracy at epoch [292]:74.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [293]: 1.6445841312408447 (Train Set)\n",
      "Accuracy at epoch [293]:74.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [294]: 1.6509584951400758 (Train Set)\n",
      "Accuracy at epoch [294]:75.24% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [295]: 1.6540219235420226 (Train Set)\n",
      "Accuracy at epoch [295]:75.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [296]: 1.6539299340248108 (Train Set)\n",
      "Accuracy at epoch [296]:75.33999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [297]: 1.6450998735427858 (Train Set)\n",
      "Accuracy at epoch [297]:75.46000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [298]: 1.638801272392273 (Train Set)\n",
      "Accuracy at epoch [298]:75.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [299]: 1.6442776384353637 (Train Set)\n",
      "Accuracy at epoch [299]:75.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [300]: 1.6342716178894043 (Train Set)\n",
      "Accuracy at epoch [300]:75.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [301]: 1.6379275345802307 (Train Set)\n",
      "Accuracy at epoch [301]:75.82% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [302]: 1.646873884677887 (Train Set)\n",
      "Accuracy at epoch [302]:75.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [303]: 1.6500593857765198 (Train Set)\n",
      "Accuracy at epoch [303]:75.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [304]: 1.6414533700942993 (Train Set)\n",
      "Accuracy at epoch [304]:75.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [305]: 1.6389729595184326 (Train Set)\n",
      "Accuracy at epoch [305]:76.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [306]: 1.6365838837623596 (Train Set)\n",
      "Accuracy at epoch [306]:75.58% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [307]: 1.644000494480133 (Train Set)\n",
      "Accuracy at epoch [307]:75.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [308]: 1.6469315052032472 (Train Set)\n",
      "Accuracy at epoch [308]:75.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [309]: 1.634665530204773 (Train Set)\n",
      "Accuracy at epoch [309]:74.48% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [310]: 1.6396931447982788 (Train Set)\n",
      "Accuracy at epoch [310]:75.38% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [311]: 1.6337061886787414 (Train Set)\n",
      "Accuracy at epoch [311]:75.3% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [312]: 1.6357524909973145 (Train Set)\n",
      "Accuracy at epoch [312]:75.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [313]: 1.633735873222351 (Train Set)\n",
      "Accuracy at epoch [313]:75.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [314]: 1.6384990501403809 (Train Set)\n",
      "Accuracy at epoch [314]:75.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [315]: 1.6343518204689025 (Train Set)\n",
      "Accuracy at epoch [315]:75.96000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [316]: 1.635737693309784 (Train Set)\n",
      "Accuracy at epoch [316]:75.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [317]: 1.6375691771507264 (Train Set)\n",
      "Accuracy at epoch [317]:76.25999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [318]: 1.6360262427330017 (Train Set)\n",
      "Accuracy at epoch [318]:75.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [319]: 1.6361923184394835 (Train Set)\n",
      "Accuracy at epoch [319]:75.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [320]: 1.63692142868042 (Train Set)\n",
      "Accuracy at epoch [320]:76.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [321]: 1.6342528281211852 (Train Set)\n",
      "Accuracy at epoch [321]:76.08% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [322]: 1.6284662742614746 (Train Set)\n",
      "Accuracy at epoch [322]:75.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [323]: 1.6357366189956666 (Train Set)\n",
      "Accuracy at epoch [323]:76.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [324]: 1.6270852999687195 (Train Set)\n",
      "Accuracy at epoch [324]:76.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [325]: 1.6283498811721802 (Train Set)\n",
      "Accuracy at epoch [325]:76.24% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [326]: 1.6295080461502076 (Train Set)\n",
      "Accuracy at epoch [326]:75.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [327]: 1.6326531081199647 (Train Set)\n",
      "Accuracy at epoch [327]:76.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [328]: 1.6378499584197999 (Train Set)\n",
      "Accuracy at epoch [328]:75.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [329]: 1.62937810754776 (Train Set)\n",
      "Accuracy at epoch [329]:76.06% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [330]: 1.6318177704811097 (Train Set)\n",
      "Accuracy at epoch [330]:76.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [331]: 1.6287095890045167 (Train Set)\n",
      "Accuracy at epoch [331]:75.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [332]: 1.6241495056152344 (Train Set)\n",
      "Accuracy at epoch [332]:76.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [333]: 1.6282935161590577 (Train Set)\n",
      "Accuracy at epoch [333]:76.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [334]: 1.6323854646682738 (Train Set)\n",
      "Accuracy at epoch [334]:75.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [335]: 1.6198936505317687 (Train Set)\n",
      "Accuracy at epoch [335]:75.72% (Test Set)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch [336]: 1.6214860849380492 (Train Set)\n",
      "Accuracy at epoch [336]:76.46% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [337]: 1.6281073713302612 (Train Set)\n",
      "Accuracy at epoch [337]:76.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [338]: 1.625630509376526 (Train Set)\n",
      "Accuracy at epoch [338]:76.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [339]: 1.6156368951797486 (Train Set)\n",
      "Accuracy at epoch [339]:76.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [340]: 1.6183114776611327 (Train Set)\n",
      "Accuracy at epoch [340]:76.25999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [341]: 1.6230465083122254 (Train Set)\n",
      "Accuracy at epoch [341]:76.8% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [342]: 1.6314069242477418 (Train Set)\n",
      "Accuracy at epoch [342]:76.7% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [343]: 1.6164336967468262 (Train Set)\n",
      "Accuracy at epoch [343]:75.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [344]: 1.6142237277030944 (Train Set)\n",
      "Accuracy at epoch [344]:76.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [345]: 1.6145085010528564 (Train Set)\n",
      "Accuracy at epoch [345]:76.6% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [346]: 1.617109456062317 (Train Set)\n",
      "Accuracy at epoch [346]:76.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [347]: 1.6194623746871948 (Train Set)\n",
      "Accuracy at epoch [347]:76.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [348]: 1.622517855167389 (Train Set)\n",
      "Accuracy at epoch [348]:76.66% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [349]: 1.6217849836349487 (Train Set)\n",
      "Accuracy at epoch [349]:76.52% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [350]: 1.6203862152099608 (Train Set)\n",
      "Accuracy at epoch [350]:76.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [351]: 1.6140164170265199 (Train Set)\n",
      "Accuracy at epoch [351]:76.22% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [352]: 1.618406681060791 (Train Set)\n",
      "Accuracy at epoch [352]:76.55999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [353]: 1.6171159887313842 (Train Set)\n",
      "Accuracy at epoch [353]:75.78% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [354]: 1.6190670557022095 (Train Set)\n",
      "Accuracy at epoch [354]:76.38000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [355]: 1.6193395595550537 (Train Set)\n",
      "Accuracy at epoch [355]:76.64% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [356]: 1.6191020011901855 (Train Set)\n",
      "Accuracy at epoch [356]:75.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [357]: 1.6136368737220763 (Train Set)\n",
      "Accuracy at epoch [357]:75.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [358]: 1.6087750401496888 (Train Set)\n",
      "Accuracy at epoch [358]:77.12% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [359]: 1.6148623700141906 (Train Set)\n",
      "Accuracy at epoch [359]:76.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [360]: 1.6145419282913207 (Train Set)\n",
      "Accuracy at epoch [360]:76.16000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [361]: 1.6096483082771302 (Train Set)\n",
      "Accuracy at epoch [361]:76.75999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [362]: 1.6081860423088075 (Train Set)\n",
      "Accuracy at epoch [362]:76.4% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [363]: 1.6074182291030883 (Train Set)\n",
      "Accuracy at epoch [363]:76.62% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [364]: 1.6034209423065187 (Train Set)\n",
      "Accuracy at epoch [364]:76.55999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [365]: 1.6056069922447205 (Train Set)\n",
      "Accuracy at epoch [365]:76.34% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [366]: 1.6098990540504456 (Train Set)\n",
      "Accuracy at epoch [366]:75.98% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [367]: 1.612486795425415 (Train Set)\n",
      "Accuracy at epoch [367]:76.86% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [368]: 1.6143391551971435 (Train Set)\n",
      "Accuracy at epoch [368]:76.9% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [369]: 1.6127631855010987 (Train Set)\n",
      "Accuracy at epoch [369]:76.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [370]: 1.605058361530304 (Train Set)\n",
      "Accuracy at epoch [370]:76.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [371]: 1.6128811469078064 (Train Set)\n",
      "Accuracy at epoch [371]:75.48% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [372]: 1.607395320415497 (Train Set)\n",
      "Accuracy at epoch [372]:76.78% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [373]: 1.5975468826293946 (Train Set)\n",
      "Accuracy at epoch [373]:76.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [374]: 1.6099909534454346 (Train Set)\n",
      "Accuracy at epoch [374]:76.75999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [375]: 1.607797025680542 (Train Set)\n",
      "Accuracy at epoch [375]:76.66% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [376]: 1.6089325227737428 (Train Set)\n",
      "Accuracy at epoch [376]:76.3% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [377]: 1.6047973794937134 (Train Set)\n",
      "Accuracy at epoch [377]:76.84% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [378]: 1.6069968452453613 (Train Set)\n",
      "Accuracy at epoch [378]:76.66% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [379]: 1.6071792130470275 (Train Set)\n",
      "Accuracy at epoch [379]:76.88000000000001% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [380]: 1.5961089272499085 (Train Set)\n",
      "Accuracy at epoch [380]:76.2% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [381]: 1.6031105322837829 (Train Set)\n",
      "Accuracy at epoch [381]:77.02% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [382]: 1.603648057937622 (Train Set)\n",
      "Accuracy at epoch [382]:77.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [383]: 1.6004583554267884 (Train Set)\n",
      "Accuracy at epoch [383]:77.16% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [384]: 1.5967453446388244 (Train Set)\n",
      "Accuracy at epoch [384]:76.53999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [385]: 1.5989447851181031 (Train Set)\n",
      "Accuracy at epoch [385]:76.62% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [386]: 1.5986876621246338 (Train Set)\n",
      "Accuracy at epoch [386]:77.03999999999999% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [387]: 1.6047315068244934 (Train Set)\n",
      "Accuracy at epoch [387]:76.44% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [388]: 1.6051110367774963 (Train Set)\n",
      "Accuracy at epoch [388]:76.72% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [389]: 1.6023472595214843 (Train Set)\n",
      "Accuracy at epoch [389]:76.68% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [390]: 1.6061963925361633 (Train Set)\n",
      "Accuracy at epoch [390]:77.0% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [391]: 1.5999536170959472 (Train Set)\n",
      "Accuracy at epoch [391]:77.18% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [392]: 1.6097969555854796 (Train Set)\n",
      "Accuracy at epoch [392]:77.14% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [393]: 1.5968057894706726 (Train Set)\n",
      "Accuracy at epoch [393]:76.92% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [394]: 1.5973678674697875 (Train Set)\n",
      "Accuracy at epoch [394]:76.42% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [395]: 1.5987787799835205 (Train Set)\n",
      "Accuracy at epoch [395]:77.28% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [396]: 1.6017078824043274 (Train Set)\n",
      "Accuracy at epoch [396]:76.4% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [397]: 1.602337959766388 (Train Set)\n",
      "Accuracy at epoch [397]:77.24% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [398]: 1.5934512667655945 (Train Set)\n",
      "Accuracy at epoch [398]:76.36% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [399]: 1.60032914686203 (Train Set)\n",
      "Accuracy at epoch [399]:76.5% (Test Set)\n",
      "\n",
      "\n",
      "Loss at epoch [400]: 1.5882014751434326 (Train Set)\n",
      "Accuracy at epoch [400]:76.86% (Test Set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Treinamento por 400 pocas\n",
    "best_model, train_losses, test_acc = train_model(model, 400, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973548,
     "status": "ok",
     "timestamp": 1555804972955,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "9i0RiPxGnHER",
    "outputId": "7bb24264-a24a-4234-e2ae-82711cf79b96"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Cross Entropy durante o Treinamento\")\n",
    "plt.tight_layout()\n",
    "_ = plt.plot(train_losses)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Accuracia durante o Treinamento\")\n",
    "plt.tight_layout()\n",
    "_ = plt.plot(test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01Tt80TJnHEU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataset, batch_size):\n",
    "  inputs_list, labels_list = [], []\n",
    "  for _, (inputs, labels) in enumerate(dataset):\n",
    "      inputs_list.append(inputs.to(device))\n",
    "      labels_list.append(labels.to(device))\n",
    "    \n",
    "  hits = 0\n",
    "  for i, (inputs, labels) in enumerate(zip(inputs_list, labels_list), 0):\n",
    "      y_pred = model(inputs)\n",
    "      for i, (pred, label) in enumerate(zip(y_pred, labels)):\n",
    "          if one_hot(pred)==label.item():\n",
    "              hits+=1\n",
    "  return hits / (len(dataset) * batch_size) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORT70P_HnHEa"
   },
   "source": [
    "# Avaliao do Modelo no dataset de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981477,
     "status": "ok",
     "timestamp": 1555804980895,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "67HW1F6qnHEb",
    "outputId": "0da03472-37d8-43f8-d860-8329cfc7a267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.824\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, train, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8Xu6D4znHEd"
   },
   "source": [
    "# Avaliao do Modelo no dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981693,
     "status": "ok",
     "timestamp": 1555804981123,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "kNDO4K7FnHEf",
    "outputId": "34c44b74-a3bf-4f1e-b01f-891f0fa9ffbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.86\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, test, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIeUfbSeroSz"
   },
   "source": [
    "# Validao do Modelo (conjunto de validao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 981927,
     "status": "ok",
     "timestamp": 1555804981364,
     "user": {
      "displayName": "Ihan Bender",
      "photoUrl": "",
      "userId": "09326755177320215938"
     },
     "user_tz": 180
    },
    "id": "WSY1Kjdart8J",
    "outputId": "321248fc-65f6-4d31-f142-e56cd3545b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.3\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(model, validation, 1000))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03 - CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
